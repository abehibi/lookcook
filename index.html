<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>スマホカメラ＋YOLOv8検出</title>
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%;
      overflow: hidden;
      background: black;
    }
    .container {
      position: relative;
      width: 100%;
      height: 100vh;
      background: black;
    }
    video, canvas {
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #toggleLight, #shutter {
      position: absolute;
      width: 100%;
      padding: 40px 20px;
      font-size: 32px;
      border: none;
      z-index: 10;
      -webkit-tap-highlight-color: transparent;
      color: white;
    }
    #toggleLight {
      top: 0;
      background: rgba(0, 0, 0, 0.5);
    }
    #shutter {
      bottom: env(safe-area-inset-bottom, 20px);
      background: rgba(255, 0, 0, 0.5);
    }
    #shutter:active {
      background: rgba(139, 0, 0, 0.7);
    }
  </style>
</head>
<body>
  <div class="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <button id="toggleLight">ライトを点ける</button>
    <button id="shutter">シャッター</button>
  </div>

  <!-- ONNX Runtime -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const shutterBtn = document.getElementById('shutter');
    const toggleLightBtn = document.getElementById('toggleLight');

    let stream, videoTrack, model;
    let torchOn = false;
    let isPaused = false;

    async function startCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" }
        });
        video.srcObject = stream;
        videoTrack = stream.getVideoTracks()[0];
      } catch (e) {
        alert('カメラを起動できませんでした。');
      }
    }

    async function loadModel() {
      model = await ort.InferenceSession.create("yolov8n.pt");
    }

    function preprocess() {
      const size = 640;
      const tmpCanvas = document.createElement('canvas');
      tmpCanvas.width = size;
      tmpCanvas.height = size;
      const tmpCtx = tmpCanvas.getContext('2d');
      tmpCtx.drawImage(video, 0, 0, size, size);
      const imgData = tmpCtx.getImageData(0, 0, size, size).data;

      const input = new Float32Array(1 * 3 * size * size);
      for (let i = 0; i < size * size; i++) {
        input[i] = imgData[i * 4] / 255;
        input[i + size * size] = imgData[i * 4 + 1] / 255;
        input[i + 2 * size * size] = imgData[i * 4 + 2] / 255;
      }

      return new ort.Tensor("float32", input, [1, 3, size, size]);
    }

    function drawDetections(boxes, scores, classIds) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      for (let i = 0; i < boxes.length; i++) {
        if (scores[i] > 0.4) {
          const [x, y, w, h] = boxes[i];
          const left = x - w / 2;
          const top = y - h / 2;

          ctx.strokeStyle = "red";
          ctx.lineWidth = 2;
          ctx.strokeRect(left, top, w, h);
          ctx.fillStyle = "red";
          ctx.font = "16px sans-serif";
          ctx.fillText(`Class ${classIds[i]}: ${scores[i].toFixed(2)}`, left, top - 5);
        }
      }
    }

    async function detectLoop() {
      if (!isPaused && model && video.readyState === 4) {
        const inputTensor = preprocess();
        const output = await model.run({ images: inputTensor });

        const out = output[Object.keys(output)[0]]; // e.g., output "output0"
        const data = out.data;
        const numDetections = data.length / 85;
        const boxes = [], scores = [], classIds = [];

        for (let i = 0; i < numDetections; i++) {
          const score = data[i * 85 + 4];
          if (score > 0.4) {
            const x = data[i * 85];
            const y = data[i * 85 + 1];
            const w = data[i * 85 + 2];
            const h = data[i * 85 + 3];
            const classId = data.slice(i * 85 + 5, i * 85 + 85).indexOf(Math.max(...data.slice(i * 85 + 5, i * 85 + 85)));

            boxes.push([x * canvas.width, y * canvas.height, w * canvas.width, h * canvas.height]);
            scores.push(score);
            classIds.push(classId);
          }
        }

        drawDetections(boxes, scores, classIds);
      }
      requestAnimationFrame(detectLoop);
    }

    toggleLightBtn.onclick = async () => {
      if (!videoTrack) return;
      const capabilities = videoTrack.getCapabilities();
      if (!capabilities.torch) {
        alert("このデバイスはライト機能をサポートしていません。");
        return;
      }

      try {
        torchOn = !torchOn;
        await videoTrack.applyConstraints({ advanced: [{ torch: torchOn }] });
        toggleLightBtn.textContent = torchOn ? "ライトを消す" : "ライトを点ける";
      } catch (e) {
        alert("ライトの切り替えに失敗しました。");
      }
    };

    shutterBtn.onclick = () => {
      if (isPaused) {
        video.play();
        shutterBtn.textContent = "シャッター";
      } else {
        video.pause();
        shutterBtn.textContent = "再開";
      }
      isPaused = !isPaused;
    };

    // 起動
    startCamera();
    loadModel().then(() => requestAnimationFrame(detectLoop));
  </script>
</body>
</html>

</body>
</html>
